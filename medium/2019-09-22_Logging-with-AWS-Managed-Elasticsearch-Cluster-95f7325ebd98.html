<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Logging with AWS Managed Elasticsearch Cluster</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Logging with AWS Managed Elasticsearch Cluster</h1>
</header>
<section data-field="subtitle" class="p-summary">
A quick description on setting up AWS managed elastic search, cognito and a cloudwatch subscription filter
</section>
<section data-field="description" class="p-summary">
A quick description on setting up AWS managed elastic search, cognito and a cloudwatch subscription filter
</section>
<section data-field="body" class="e-content">
<section name="7f75" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7c58" id="7c58" class="graf graf--h3 graf--leading graf--title">Logging with an AWS Managed Elasticsearch Cluster</h3><h4 name="b14c" id="b14c" class="graf graf--h4 graf-after--h3 graf--subtitle">A quick introduction to setting up AWS managed elasticsearch, kibana, cognito and cloudwatch subscription filters</h4><h3 name="521b" id="521b" class="graf graf--h3 graf-after--h4">Introduction</h3><figure name="b331" id="b331" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*uDaNucTE5hJpx8Bu-zkk5w.jpeg" data-width="638" data-height="359" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*uDaNucTE5hJpx8Bu-zkk5w.jpeg"><figcaption class="imageCaption">Overview of some of the places you will receive logs in AWS directed at an ES cluster. ©JasonPoley</figcaption></figure><p name="d1b9" id="d1b9" class="graf graf--p graf-after--figure"><em class="markup--em markup--p-em">Logging and monitoring your infrastructure sounds easier than it is.</em></p><p name="bb49" id="bb49" class="graf graf--p graf-after--p">The first issue is all the different services you will need to pay attention to. The diagram above only covers some AWS services, you will usually be using other external services like databases outside of your AWS infrastructure as well.</p><p name="be75" id="be75" class="graf graf--p graf-after--p">The next issue is for each component you will need to consider how you get you data securely to elasticsearch or whatever stash your are using.</p><p name="20fa" id="20fa" class="graf graf--p graf-after--p">Lastly, all your logs will need some processing since some of the components will inherently produce different formats even if your applications use a consistent format. This can be done with logstash, a lambda or some other tool. Logstash is powerful but the majority of of our logs will come from cloudwatch logs so we can use a simple lambda subscription to securely collect, format and then send them to our stash.</p><p name="eaa2" id="eaa2" class="graf graf--p graf-after--p">With these setup we can create new cloudwatch groups and streams for any component inside or outside AWS and forward our logs to it. Of course you don’t need to go down this route since any pipelines to ES would suffice. It just makes life easier to have a single entry point for the majority of our logs.</p><h3 name="b543" id="b543" class="graf graf--h3 graf-after--p">Elasticsearch (ES)</h3><p name="0422" id="0422" class="graf graf--p graf-after--h3"><em class="markup--em markup--p-em">Why use ES anyway?</em></p><p name="6d3b" id="6d3b" class="graf graf--p graf-after--p">You will always need a central place to aggregate logs from all areas of you infrastructure. That is if you want to fully automate your components. You don’t want devs jumping between database logs, cloud metrics and application logs to try and get a picture of what went wrong. You want a single store of truth which unifies all logs from all systems. This is a lot of work but you don’t have to do it all at once. Pick the logs you really need and write the lambda business logic for it. If you suddenly need more info, say from mongodb then</p><ol class="postList"><li name="7b4f" id="7b4f" class="graf graf--li graf-after--p">Forward mongodb logs to cloudwatch group</li><li name="16c3" id="16c3" class="graf graf--li graf-after--li">Update subscription lambda to deal with new format of logs</li></ol><p name="89ff" id="89ff" class="graf graf--p graf-after--li">You can repeat this for any system adding more and more information about your infrastructure to your stash. You can, of course, forward your logs directly to ES but we found it easier to have a single point of contact for all logs when possible.</p><p name="9cee" id="9cee" class="graf graf--p graf-after--p">Elasticsearch was chosen since it is one of the best and most widely used search engines. Other tools and services are available like papertrail or logly but you will need to play with each one since they all have different use cases and costs. In particular the AWS managed cluster was chosen for ease of setup. You can also setup the cluster yourself on EC2 instances but this in most cases is not needed. Additionally you can pay elastic rather than AWS to setup you cluster.</p><p name="7e24" id="7e24" class="graf graf--p graf-after--p">In nearly all cases you will want to have kibana running with ES. Kibana is a frontend for ES. You can manipulate your data easily with many premade tools without have to write searches and then plot the results.</p><figure name="5765" id="5765" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://giphy.com/embed/XeLcgh8gT8o0F5SQ8i/twitter/iframe" width="435" height="326" frameborder="0" scrolling="no"></iframe><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong"><em class="markup--em markup--figure-em">In the end, anything has to be better than cloudwatch so pick the best thing for you.</em></strong></figcaption></figure><h3 name="e5d7" id="e5d7" class="graf graf--h3 graf-after--figure">Creating the Resources</h3><p name="7bf0" id="7bf0" class="graf graf--p graf-after--h3">Terraform was used to describe the full setup.</p><h4 name="eae5" id="eae5" class="graf graf--h4 graf-after--p">AWS Managed ElasticSearch</h4><p name="5150" id="5150" class="graf graf--p graf-after--h4">The managed ES cluster secures its search endpoint using an access policy which dictates what roles can access what ES indices. Your EC2 instance must be greater than or equal to 3 so ES can split the shards between multiple elastic blocks attached to each EC2 instance.</p><p name="b2f8" id="b2f8" class="graf graf--p graf-after--p">Snapshots are taken every 23 hours to backup your data.</p><figure name="4446" id="4446" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/mortonprod/267103bb919bd3a4e4c67a3608776fdf.js"></script></figure><p name="74e1" id="74e1" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Note: We ignore the cognito options. This is done since we allow ES to create the cognito client for us which means it is out of terraforms state. We could try to import this state afterwards but it’s not worth the effort.</em></strong></p><h4 name="940d" id="940d" class="graf graf--h4 graf-after--p">Cognito</h4><p name="cee9" id="cee9" class="graf graf--p graf-after--h4">Cognito secures Kibana using an OAuth authorization code grant. This works with the access policy using the following process:</p><ol class="postList"><li name="755e" id="755e" class="graf graf--li graf-after--p">Kibana will direct to the cognito userpool when you visit the page</li><li name="ca4c" id="ca4c" class="graf graf--li graf-after--li">You will login and get an auth code which you exchange for an access token using the authorization code grant flow</li><li name="cfef" id="cfef" class="graf graf--li graf-after--li">Kibana forwards access token onto identity pool</li><li name="e2e4" id="e2e4" class="graf graf--li graf-after--li">The identity pool validates the token, checks the groups listed in the token and associates the role from the group with the highest precedence to it</li></ol><p name="4388" id="4388" class="graf graf--p graf-after--li">If the role matches the principle in the ES access policy then you can login.</p><p name="1966" id="1966" class="graf graf--p graf-after--p">We need to create all of this for it to work so we next create the roles, user pool and identity pool. We then attach the roles to a particular user pool group.</p><p name="005b" id="005b" class="graf graf--p graf-after--p">As mentioned above, you must configure the identity pool to use the role specified with the user pool group over its own authenticated role.</p><p name="736e" id="736e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Note: This is not specified in terraform and must be done using the AWS console. I have to check if this is possible but my setup does not change state on each apply so this is not to much of a concern right now.</em></strong></p><figure name="37a8" id="37a8" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/mortonprod/74712d1cb7e620114bdcf14cbbcb10f2.js"></script></figure><h4 name="3ad9" id="3ad9" class="graf graf--h4 graf-after--figure">Subscription Lambda</h4><p name="500e" id="500e" class="graf graf--p graf-after--h4">The subscription lambda is the last part to this. Another option is to use a kinesis stream to ES rather than a subscription. If your setup starts with large throughput this might be the better option. We did not need this right away so kinesis was left for future development.</p><p name="3ad1" id="3ad1" class="graf graf--p graf-after--p">The lambda needs the correct execution role to run. We then deploy it, ready for us to subscribe this to every cloudwatch group in all regions.</p><figure name="9f84" id="9f84" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/mortonprod/734ff78712a040b5736ac53edaf7da00.js"></script></figure><p name="3f32" id="3f32" class="graf graf--p graf-after--figure">The lambda itself is a pretty easy build and will depending on exactly what you need. In our case we had to also build a slack integration which notifies a when an error has occurred. Assuming all you want to do is forward logs to ES then you only need to consider the format of the ES log and secure the request. Below you can see an example of this.</p><figure name="481f" id="481f" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/mortonprod/427224d34fb2ae765551f0f276025bee.js"></script></figure><p name="d876" id="d876" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Note: You need to package the AWS id and secret into the headers.</em></strong> <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">This was a surprise to me since I assumed AWS would deal with this process like many other services but I could not get this to work without it. There are full examples of this online which I used so you should be able to find more information if need be.</em></strong></p><h4 name="48e0" id="48e0" class="graf graf--h4 graf-after--p">Lambda Subscription Tool</h4><p name="4968" id="4968" class="graf graf--p graf-after--h4">The lambda must be subscribed to all the cloudwatch groups in all regions. This makes using terraform to orchestrate the subscription problematic since we should have to initialise a new provider for each region. Furthermore, terraform loses track of state in arrays if the array is reordered. This will cause the subscription to be renewed for many groups which already has one.</p><p name="df95" id="df95" class="graf graf--p graf-after--p">Therefore it was easier to keep the subscription part outside of terraform using a simple build tool which we run every-time we create a new cloudwatch group.</p><figure name="86f3" id="86f3" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/mortonprod/97304f9a2623c6e0b98407202a7efc41.js"></script></figure><p name="19a3" id="19a3" class="graf graf--p graf-after--figure">This might seem over kill since the majority of your resources will be in a single region but this is not always the case. As an example: If you are using cloudfront and edge lambdas then you can’t be sure where the request will be processed so you may have logs in many different regions.</p><h3 name="f219" id="f219" class="graf graf--h3 graf-after--p">Maintainance</h3><p name="459a" id="459a" class="graf graf--p graf-after--h3">There are a few things you will need to do regularly:</p><ul class="postList"><li name="3ad2" id="3ad2" class="graf graf--li graf-after--p">Cron job to remove old indices and data if no longer required</li><li name="bd52" id="bd52" class="graf graf--li graf-after--li">Need fix/remove old visualise with old indices</li><li name="a69c" id="a69c" class="graf graf--li graf-after--li">Need to rerun build tool anytime we add a new log group</li></ul><p name="e14c" id="e14c" class="graf graf--p graf-after--li">This is a small list compared to what we would have to do to maintain our own cluster. ES updates are also managed by AWS with very little downtime.</p><h3 name="d219" id="d219" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="86f9" id="86f9" class="graf graf--p graf-after--h3">With all of this completed, we can now start to produce visuals of all inputs we have provided. We run our search and get kibana to output the results. Below you can see two simple examples.</p><figure name="727f" id="727f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Gp--IqZeZo4zZ5SJSr8mOA.jpeg" data-width="1160" data-height="1070" src="https://cdn-images-1.medium.com/max/800/1*Gp--IqZeZo4zZ5SJSr8mOA.jpeg"><figcaption class="imageCaption">This is the number of log streams from each app</figcaption></figure><p name="c6da" id="c6da" class="graf graf--p graf-after--figure">One of the most impressive thing you get out of the box, if you timestamp your data correctly, is time dependent graphs. This allows you to quickly understand how your applications and infrastructure are performing throughout the day.</p><figure name="7efb" id="7efb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*zZmJNucMci9I7wqwHkmkiA.jpeg" data-width="1481" data-height="860" src="https://cdn-images-1.medium.com/max/800/1*zZmJNucMci9I7wqwHkmkiA.jpeg"><figcaption class="imageCaption">This is the number of logs from each app vs time</figcaption></figure><p name="7047" id="7047" class="graf graf--p graf-after--figure graf--trailing"><em class="markup--em markup--p-em">There is much more you can do with this tool which I do not cover. I hope this quick guide is of use to yourself and quite possibly my future self.</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@mortonprod" class="p-author h-card">Alexander Morton</a> on <a href="https://medium.com/p/95f7325ebd98"><time class="dt-published" datetime="2019-09-22T13:23:51.219Z">September 22, 2019</time></a>.</p><p><a href="https://medium.com/@mortonprod/logging-with-aws-managed-elasticsearch-cluster-95f7325ebd98" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 24, 2021.</p></footer></article></body></html>